{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOBcMIarTt+mAc2Vdt3leaO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%%capture\n","import os\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth\n","else:\n","    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n","    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n","    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n","    !pip install --no-deps unsloth\n","    !pip install wandb"],"metadata":{"id":"WFu8hJxE8UcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qQEy-GS8O0d"},"outputs":[],"source":["from unsloth import FastLanguageModel, PatchDPOTrainer, is_bfloat16_supported\n","from peft import LoraConfig\n","from trl import DPOTrainer, DPOConfig\n","from datasets import load_dataset\n","import torch\n","import pandas as pd\n","from datasets import Dataset\n","\n","PatchDPOTrainer()\n","\n","# Select one from the list\n","\"\"\"\n","model_sizes = [\n","    \"Qwen/Qwen2.5-1.5B-Instruct\",\n","    \"Qwen/Qwen2.5-3B-Instruct\",\n","    \"Qwen/Qwen2.5-7B-Instruct\",\n","    \"Qwen/Qwen2.5-14B-Instruct\",\n","]\n","\"\"\"\n","\n","_, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"Qwen/Qwen2.5-7B-Instruct\",\n","    max_seq_length = 1024,\n","    dtype = None,\n","    load_in_4bit = True,\n",")"]},{"cell_type":"markdown","source":["# Data prep"],"metadata":{"id":"i1TqYFoqthdn"}},{"cell_type":"code","source":["def make_splits(full_ds, pct: float, val_frac: float = 0.1, seed: int = 42):\n","    \"\"\"\n","    - pct: fraction of full_ds to sample (e.g. 0.1 or 0.4)\n","    - val_frac: fraction of that slice to hold out for eval\n","    \"\"\"\n","    # sample your slice\n","    n_slice = int(len(full_ds) * pct)\n","    slice_ds = full_ds.shuffle(seed=seed).select(range(n_slice))\n","\n","    # split off validation\n","    n_val = int(len(slice_ds) * val_frac)\n","    eval_ds  = slice_ds.select(range(n_val))\n","    train_ds = slice_ds.select(range(n_val, len(slice_ds)))\n","\n","    return train_ds, eval_ds"],"metadata":{"id":"vuy-8qDj9Uyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Upload the dpo-train parquet to the files\n","df = pd.read_parquet(\"/content/dpo-train-00000-of-00001.parquet\")\n","full = Dataset.from_pandas(df)\n","\n","train_dataset, eval_dataset = make_splits(full, pct=1, seed=42)\n","print(f\"10% slice â†’ train: {len(train_dataset)}, eval: {len(eval_dataset)}\")"],"metadata":{"id":"AbhfDXvt9WUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_chat_template(example, tokenizer, task):\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": example[\"prompt\"]},\n","    ]\n","\n","    chat_prompt = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True,\n","    )\n","\n","    return {\n","        \"text_prompt\": chat_prompt,\n","        \"text_chosen\": chat_prompt + example[\"chosen\"].strip(),\n","        \"text_rejected\": chat_prompt + example[\"rejected\"].strip(),\n","    }"],"metadata":{"id":"YhtrSYOz9S9C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_and_rename(ds):\n","    old_cols = ds.column_names\n","    ds2 = ds.map(\n","        apply_chat_template,\n","        fn_kwargs      = {\"tokenizer\": tokenizer, \"task\": \"dpo\"},\n","        num_proc       = 4,\n","        batched        = False,\n","        remove_columns = old_cols,\n","        desc           = \"Formatting for DPO\",\n","    )\n","    return ds2.rename_columns({\n","        \"text_prompt\":   \"prompt\",\n","        \"text_chosen\":   \"chosen\",\n","        \"text_rejected\": \"rejected\",\n","    })\n","\n","\n","formatted_train = format_and_rename(train_dataset)\n","formatted_eval = format_and_rename(eval_dataset)"],"metadata":{"id":"yXW7u9VN9TTm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(formatted_train[0])\n","print(\"Train columns:\", formatted_train.column_names)\n","print(\"Eval columns:\", formatted_eval.column_names)"],"metadata":{"id":"w4KUMcns948p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Prompt: \\n\" + formatted_train[0]['prompt'] + \"\\n\")\n","print(\"Chosen: \\n\" + formatted_train[0]['chosen'] + \"\\n\")\n","print(\"Rejected: \\n\" + formatted_train[0]['rejected'] + \"\\n\")"],"metadata":{"id":"ms2v5j7ttZDt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model training"],"metadata":{"id":"mPDhmgCWtkeu"}},{"cell_type":"code","source":["from unsloth import FastLanguageModel, PatchDPOTrainer, is_bfloat16_supported\n","from trl import DPOTrainer, DPOConfig\n","import torch\n","import wandb\n","\n","PatchDPOTrainer()\n","\n","# Same model as in the beginning\n","model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = model_name,\n","    max_seq_length = 1024,\n","    dtype = None,\n","    load_in_4bit = True\n",")\n","\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 64,\n","    lora_dropout = 0, # Currently only supports dropout = 0\n","    bias = \"none\",    # Currently only supports bias = \"none\"\n","    use_gradient_checkpointing = True, # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")\n","\n","config = DPOConfig(\n","    per_device_train_batch_size   = 2,\n","    gradient_accumulation_steps   = 4,\n","    warmup_ratio                  = 0.1,\n","    num_train_epochs              = 3,\n","    learning_rate                 = 5e-6,\n","    fp16                          = not is_bfloat16_supported(),\n","    bf16                          = is_bfloat16_supported(),\n","    logging_steps                 = 50,\n","    optim                         = \"adamw_8bit\",\n","    weight_decay                  = 0.0,\n","    lr_scheduler_type             = \"linear\",\n","    seed                          = 42,\n","    output_dir                    = f\"outputs_qwen_{model_name.split('-')[1]}\",\n","    report_to                     = \"none\", # Can use Weights & Biases\n","    eval_strategy                 = \"epoch\",\n","    save_strategy                 = \"epoch\",\n",")\n","\n","trainer = DPOTrainer(\n","    model               = model,\n","    ref_model           = None,\n","    args                = config,\n","    train_dataset       = formatted_train,\n","    eval_dataset        = formatted_eval,\n","    tokenizer           = tokenizer,\n","    beta                = 0.1,\n","    max_length          = 1024,\n","    max_prompt_length   = 512,\n",")\n","\n","trainer.train()"],"metadata":{"id":"uTYiiPCE-M-z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Download best checkpoint"],"metadata":{"id":"kZ5iVc3TeDT-"}},{"cell_type":"code","source":["import shutil\n","import os\n","from google.colab import files\n","from zipfile import ZipFile\n","\n","def download_lora_checkpoint(checkpoint_folder):\n","    zip_filename = checkpoint_folder + \"_dpo.zip\"\n","\n","    # Files to include\n","    files_to_keep = [\n","        \"adapter_model.safetensors\", \"adapter_config.json\",\n","        \"tokenizer.json\", \"tokenizer_config.json\",\n","        \"vocab.json\", \"merges.txt\", \"special_tokens_map.json\",\n","        \"added_tokens.json\"\n","    ]\n","\n","    # Create zip with only the essential files\n","    with ZipFile(zip_filename, 'w') as zipf:\n","        for file_name in files_to_keep:\n","            file_path = os.path.join(checkpoint_folder, file_name)\n","            if os.path.exists(file_path):\n","                zipf.write(file_path, os.path.join(os.path.basename(checkpoint_folder), file_name))\n","\n","    files.download(zip_filename)\n","\n","\n","download_lora_checkpoint(\"/content/outputs_qwen_7B/checkpoint-411\") # Select the best checkpoint"],"metadata":{"id":"X9_kc5aveC7g"},"execution_count":null,"outputs":[]}]}